---
title: ""
output:
  html_document:
    df_print: paged
    includes:
      in_header: header.html
---
<center>
<p style="text-align: center;">
<h2> Módulo 1</h2>
Juan Zamora O.
</p>
</center>

## Introducción

El principal objetivo del Curso es *exponer a los alumnos* a una *experiencia de consultoría real*. 
Por lo tanto, el foco está puesto en resolver un problema mediante las herramientas adquiridas en el 
transcurso del Programa. Para poner esto en practica, cada uno de los 3 módulos 
consistirá en resolver (por parte de Uds.) un problema.

### Acerca de la evaluación general

Cada profesor evaluará el trabajo realizado en su módulo y con ello entregará una nota. Para el cálculo 
de la nota final se realizará un promedio simple de estas 3 notas. 


### Acerca de la modalidad de trabajo y evaluación de este módulo


El trabajo será realizado en ~grupos~ equipos. No habrá entrega de contenidos conceptuales. En clases, 
el profesor se irá reuniendo con los grupos para discutir y orientar los avances alcanzados. 

**Será necesario que cada grupo tenga avances antes de cada sesión**. La idea de esto es que 
exista un insumo que motive la discusión dentro de cada grupo y participación del Profesor.

La nota final de este módulo consistirá del promedio entre dos notas parciales: Una asociada al informe final y otra a la presentación final. La nota del informe
se replica para todos los miembros del equipo. En la presentación final, cada miembro deberá exponer y recibirá su nota
de acuerdo a lo observado por el Profesor. La ausencia de exposición tendrá nota mínima.


## El problema de la Recomendación

El escenario que ustedes deberan enfrentar es aquel en que dado un usuario, su historia de preferencias y la información de otros usuarios, se requiere entregarle "buenas" sugerencias. Estas sugerencias deben ser coherentes con los gustos del usuario y para ello deberan ser obtenidas algún tipo de criterio. *Por ejemplo*, este criterio puede considerar aquellos ítems que maximizacen de la valoración esperada por parte del usuario o que tengan información textual (tags por ejemplo) que se aleje minimamente de aquella asociada al usuario.

Ejemplos de este problema pueden observarse en muchos dominios distintos. Por ejemplo, recomendación de productos a usuarios en sitios de ventas en línea (amazon, ebay, falabella on-line ...), recomendación de contenido en plataformas multimedia que consiga mantener a los usuarios "consumiendo". El insumo (*input*) para este tipo de métodos consiste de información relativa a los usuarios, ítems, contextos de consumo y retroalimentación de los usuarios luego de interactuar con los ítems.

## Conjunto de datos

Se tiene una base de datos con información de películas (título, año, genero ...) y
también de valoraciones de los usuarios (puntuación y etiquetas asignadas).

### Descarga del conjunto de datos

```{r}
dl <- paste(tempfile(),".zip",sep = "")
download.file("http://files.grouplens.org/datasets/movielens/ml-latest-small.zip", dl)
unzip(dl, list = TRUE) # shows the content
unzip(dl, exdir = getwd()) # extracts into the working dir.
rm(dl)
```

### Librerías necesarias para los ejemplos

```{r load-packages, include=TRUE}
library(tidyr)
library(scales)
library(lubridate)
library(ggthemes)
library(ggplot2)
library(dplyr)
library(caret)
library(lubridate)
```

### Carga de los datos

Luego de revisar y ejecutar el script `descarga_dataset.R`, se dispondrá de 3 archivos:
```{r}

# Lectura de cada uno de los 3 archivos
ratings <- read.csv("ml-latest-small/ratings.csv")
movies <- read.csv("ml-latest-small/movies.csv")
tags <- read.csv("ml-latest-small/tags.csv")


# Unión de todos los archivos para  poder ejecutar los ejemplos 
# (no tiene porque seguir esto mismo en su propuesta)
movielens <- left_join(ratings, movies, by = "movieId")
```
### Periodo de tiempo comprendido

```{r}
tibble(`Fecha inicial` = date(as_datetime(min(movielens$timestamp), origin="1970-01-01")),
       `Fecha final` = date(as_datetime(max(movielens$timestamp), origin="1970-01-01"))) %>%
  mutate(Periodo = duration(max(movielens$timestamp)-min(movielens$timestamp)))
```


### Valoraciones por año


```{r}
# number of ratings per year
movielens %>% mutate(year = year(as_datetime(timestamp, origin="1970-01-01"))) %>%
  ggplot(aes(x=year)) +
  geom_histogram(color = "white") + 
  ggtitle("Cantidad de valoraciones por año") +
  xlab("Año") +
  ylab("Cantidad de Valoraciones") +
  scale_y_continuous(labels = comma) + 
  theme_fivethirtyeight()
``` 

### Ítem de la escala de Valoraciones

```{r}
movielens %>% group_by(rating) %>% summarize(n=n())
```


```{r}
movielens %>% group_by(rating) %>% 
  summarise(count=n()) %>%
  ggplot(aes(x=rating, y=count)) + 
  geom_line() +
  geom_point() +
  scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
                labels = trans_format("log10", math_format(10^.x))) +
  ggtitle("Distribución de valoraciones", subtitle = "Valoraciones altas son predominantes.") + 
  xlab("Rating") +
  ylab("Count") +
  theme_fivethirtyeight()

```

### Valoraciones por película


```{r}
movielens %>% group_by(movieId) %>%
  summarise(n=n()) %>%
  ggplot(aes(n)) +
  geom_histogram(color = "white") +
  scale_x_log10() + 
  ggtitle("Cantidad de valoraciones por película", 
          subtitle = "Mayoría de películas tiene menos de 1000 valoraciones.") +
  xlab("Número de valoraciones") +
  ylab("Número de películas") + 
  theme_fivethirtyeight()
```

### Valoraciones por usuario

```{r}
 movielens  %>% group_by(userId) %>%
  summarise(n=n()) %>%
  ggplot(aes(n)) +
  geom_histogram(color = "white") +
  scale_x_log10() + 
  ggtitle("Cantidad de valoraciones por usuario", 
          subtitle="Distribución con sesgo a la derecha.") +
  xlab("Cantidad de valoraciones") +
  ylab("Cantidad de usuarios") + 
  scale_y_continuous(labels = comma) + 
  theme_fivethirtyeight()
```

### _Sparsity_ en la asociación de usuarios y películas valoradas

```{r}
users <- sample(unique(movielens$userId), 100)
movielens %>% filter(userId %in% users) %>%
  select(userId, movieId, rating) %>%
  spread(movieId, rating) %>% 
  select(sample(ncol(.), 100)) %>% 
  as.matrix() %>% t(.) %>%
  image(1:100, 1:100,. , xlab="Películas", ylab="Usuarios")
abline(h=0:100+0.5, v=0:100+0.5, col = "grey")
title("Matriz de Usuarios vs Películas")
```

## Evaluación de recomendaciones

Consideremos la matriz sparse presentada antes.


Para evaluar la calidad de las recomendaciones realizadas por cualquier método que 
construyamos utilizaremos una estrategia _de validación cruzada *Hold-out*. 
Para implementar esta estrategia deberemos dividir (al azar) los datos (las valoraciones)
en $3$ partes: Entrenamiento ($\%80$), Prueba ($\%10$) y Validación ($\%10$).

```{r}
set.seed(1)

val_index <- createDataPartition(y = movielens$rating, 
                                  times = 1, p = 0.1, list = FALSE)
tr_tst_set <- movielens[-val_index,]
temp <- movielens[val_index,]

# Nos aseguramos de que cada usuario y cada película esten en ambos segmentos
validation <- temp %>% 
  semi_join(tr_tst_set, by = "movieId") %>%
  semi_join(tr_tst_set, by = "userId")

# Agregamos lo que fue filtrado del segmento de validacion al set de entr. y prueba
removed <- anti_join(temp, validation)
tr_tst_set <- rbind(tr_tst_set, removed)
```


Para continuar con la generación del conjunto de entrenamiento y prueba, deberemos dividir `tr_tst_set` en dos partes (entrenamiento y prueba). 


```{r}

# Entrenamiento 90% y prueba 10% (a partir del segmento que contenía el 90% de los datos).
set.seed(1)
test_index <- createDataPartition(y = tr_tst_set$rating, times = 1, p = 0.1, list = FALSE)
train_set <- tr_tst_set[-test_index,]
temp <- tr_tst_set[test_index,]

# Make sure userId and movieId in test set are also in train set
test_set <- temp %>% 
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")

# Add rows removed from test set back into train set
removed <- anti_join(temp, test_set)
train_set <- rbind(train_set, removed)


rm(val_index, test_index, tr_tst_set, temp, removed)
```

#### Entrenando y midiendo la calidad de los modelos

**Primero**, la calidad de las recomendaciones será medida mediante el *Error absoluto promedio* y la [*raíz del error cuadrático medio*](https://es.wikipedia.org/wiki/Ra%C3%ADz_del_error_cuadr%C3%A1tico_medio). 

```{r}
MAE <- function(true_ratings, predicted_ratings){
  mean(abs(true_ratings - predicted_ratings))
}

MSE <- function(true_ratings, predicted_ratings){
  mean((true_ratings - predicted_ratings)^2)
}

RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
```

**Entonces**, para construir cualquier modelo se usará el segmento de entrenamiento. Luego, para seleccionar aquella configuración de parámetros que permite obtener el mejor modelo se usará el segmento de prueba.

**Finalmente**, para evaluar la capacidad de generalización de cada modelo seleccionado se usará el segmento de validación.

### Modelo lineal constante $\hat{y}=\mu$

```{r}
# Promedio de las valoraciones observadas
mu <- mean(train_set$rating)

# Se llena la tabla de resultados (irá cambiando al agregar más modelos)
result <- bind_rows(tibble(Método = "Mu", 
                           RMSE = RMSE(test_set$rating, mu),
                           MSE  = MSE(test_set$rating, mu),
                           MAE  = MAE(test_set$rating, mu)))
result
```

### Modelo lineal constante $\hat{y}=\mu + b_i$

Se considera el sesgo en las valoraciones propio de cada película (hay películas más populares que otras).

```{r}
# efecto de cada película (bi)
bi <- train_set %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu))

head(bi)

# Visualización del sesgo de las películas
bi %>% ggplot(aes(x = b_i)) + 
  geom_histogram(bins=10, col = I("black")) +
  ggtitle("Distribución del efecto de las películas") +
  xlab("efecto") +
  ylab("Cantidad") +
  scale_y_continuous(labels = comma) + 
  theme_fivethirtyeight()
```

Predicciones con  $\mu + bi$

```{r}
y_hat_bi <- mu + (test_set %>% 
  left_join(bi, by = "movieId") %>% 
  .$b_i)

# Se calculan medidas de error y se actualiza la tabla  
result <- bind_rows(result, 
                    tibble(Método = "Mu + bi", 
                           RMSE = RMSE(test_set$rating, y_hat_bi),
                           MSE  = MSE(test_set$rating, y_hat_bi),
                           MAE  = MAE(test_set$rating, y_hat_bi)))

result
```

### Modelo lineal constante $\hat{y}=\mu + b_i + b_u$

Se considering el sesgo de los usuarios.

```{r}
# Efecto de cada usuario (bu)
bu <- train_set %>% 
  left_join(bi, by = 'movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))

# Predicciones
y_hat_bi_bu <- test_set %>% 
  left_join(bi, by='movieId') %>%
  left_join(bu, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%
  .$pred

# Se calculan medidas de error y se actualiza la tabla  
result <- bind_rows(result, 
                    tibble(Método = "Mu + bi + bu", 
                           RMSE = RMSE(test_set$rating, y_hat_bi_bu),
                           MSE  = MSE(test_set$rating, y_hat_bi_bu),
                           MAE  = MAE(test_set$rating, y_hat_bi_bu)))

result
```

## Referencias útiles

Relacionadas con Sistemas de Recomendación:

* [Recommender Systems: The Textbook ](https://amzn.to/3ioS6gi). Aggarwal, C., 2016. [(descargar)](https://bit.ly/3iukxtd)
* [Recommender Systems: An Introduction](https://amzn.to/3kI5vCf). Jannach et al., 2011. [(descargar)](https://bit.ly/2XPmk46) (ver cáp.II)
* [Statistical Methods for Recommender Systems](https://www.amazon.com/-/es/Deepak-K-Agarwal/dp/1107036070). Agarwal, D., & Chen, B., 2016. (ver sec. 2.4)

Otras complementarias:

* [Machine Learning with R](https://www.springer.com/gp/book/9789811068072). Ghatak, A., 2017. [(Descargar)](https://bit.ly/3ium56v)(ver cáp. I)

